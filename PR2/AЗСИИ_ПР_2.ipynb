{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Выполнил Лялин Илья Евгеньевич ББМО-02-24"
      ],
      "metadata": {
        "id": "V3ehX6sfZTaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1)Копируем проект**"
      ],
      "metadata": {
        "id": "H_fcuvhHZ82R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Va9USFidh9O",
        "outputId": "208c33d7-a63c-4a29-dee4-b44d460b4404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEL6812_DeepFool_Project'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 96 (delta 2), reused 1 (delta 1), pack-reused 93 (from 1)\u001b[K\n",
            "Receiving objects: 100% (96/96), 33.99 MiB | 14.70 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ewatson2/EEL6812_DeepFool_Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Меням директорию на папку с проектом**"
      ],
      "metadata": {
        "id": "UbndoUCtaFcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EEL6812_DeepFool_Project"
      ],
      "metadata": {
        "id": "C_TGDSs4fSXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ae4126-7b92-4fae-f06d-1a240e765321"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEL6812_DeepFool_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Импортируем библиотеки**"
      ],
      "metadata": {
        "id": "Wrtq5KvVaUhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # предоставляет поддержку многомерных массивов и математических функций\n",
        "import json # текстовый формат для хранения и передачи структурированных данных\n",
        "import torch # PyTorch - фреймворк для машинного обучения с автоматическим дифференцированием\n",
        "\n",
        "# - DataLoader: класс для загрузки данных батчами (пакетами)\n",
        "# - random_split: функция для случайного разделения набора данных на части\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# - datasets: содержит популярные наборы данных (MNIST, CIFAR, ImageNet и др.)\n",
        "# - models: предоставляет предобученные архитектуры нейронных сетей (ResNet, VGG, etc.)\n",
        "from torchvision import datasets, models\n",
        "\n",
        "# Импорт модуля transforms из torchvision для преобразований изображений:\n",
        "# содержит функции для аугментации и предобработки данных (изменение размера, нормализация и т.д.)\n",
        "from torchvision.transforms import transforms"
      ],
      "metadata": {
        "id": "lr4X1x7nfpy5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - FC_500_150: полносвязная сеть со слоями 500 и 150 нейронов\n",
        "# - LeNet_CIFAR: архитектура LeNet, адаптированная для датасета CIFAR\n",
        "# - LeNet_MNIST: архитектура LeNet, адаптированная для датасета MNIST\n",
        "# - Net: базовая или кастомная архитектура нейронной сети\n",
        "from models.project_models import FC_500_150, LeNet_CIFAR, LeNet_MNIST, Net\n",
        "\n",
        "# - get_clip_bounds: функция для получения границ обрезки значений (например, для ограничения пикселей)\n",
        "# - evaluate_attack: функция для оценки эффективности атаки на модель\n",
        "# - display_attack: функция для визуализации результатов атаки\n",
        "from utils.project_utils import get_clip_bounds, evaluate_attack, display_attack"
      ],
      "metadata": {
        "id": "jDWDjSkPf3Ut"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Устанавливаем случайное рандомное значение**\n",
        "Для rand_seed = порядковый номер студента в таблице"
      ],
      "metadata": {
        "id": "x10c5ABuaYZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_seed = 6"
      ],
      "metadata": {
        "id": "WiT0XcDAf-o2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# для numpy\n",
        "np.random.seed(rand_seed)\n",
        "# для torch\n",
        "torch.manual_seed(rand_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGUP0oJbh7ty",
        "outputId": "8d974a48-ece0-4bb3-cac0-fef6ce02dc8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c9ad4544570>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Среда выполнения сменяна на T4 GPU."
      ],
      "metadata": {
        "id": "argl8xc8i0Ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Загружаем датасет MNIST с параметрами**"
      ],
      "metadata": {
        "id": "fJK0NZ6palch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение параметров нормализации для MNIST\n",
        "mnist_mean = 0.5  # среднее значение для нормализации\n",
        "mnist_std = 0.5   # стандартное отклонение для нормализации\n",
        "mnist_dim = 28    # размер изображения MNIST (28x28 пикселей)\n",
        "\n",
        "# Вычисление минимальных и максимальных допустимых значений после нормализации\n",
        "# (важно для adversarial attacks - чтобы не выходить за допустимые границы пикселей)\n",
        "mnist_min, mnist_max = get_clip_bounds(mnist_mean, mnist_std, mnist_dim)\n",
        "\n",
        "# Определение устройства для вычислений: GPU если доступен, иначе CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Перенос граничных значений на выбранное устройство (для совместимости с тензорами)\n",
        "mnist_min = mnist_min.to(device)\n",
        "mnist_max = mnist_max.to(device)\n",
        "\n",
        "# Базовые преобразования для тестовых данных:\n",
        "# - ToTensor(): конвертация в тензор и нормализация в [0,1]\n",
        "# - Normalize(): стандартизация с заданными mean и std\n",
        "mnist_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mnist_mean, std=mnist_std)\n",
        "])\n",
        "\n",
        "# Расширенные преобразования для тренировочных данных (с аугментацией):\n",
        "# - RandomHorizontalFlip(): случайное горизонтальное отражение (для MNIST не всегда уместно)\n",
        "# - Остальные преобразования аналогичны базовым\n",
        "mnist_tf_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mnist_mean, std=mnist_std)\n",
        "])\n",
        "\n",
        "# Обратные преобразования для денормализации изображений:\n",
        "# Восстанавливает оригинальные значения пикселей после нормализации\n",
        "mnist_tf_inv = transforms.Compose([\n",
        "    transforms.Normalize(mean=0.0, std=1.0 / mnist_std),  # отмена std\n",
        "    transforms.Normalize(mean=-mnist_mean, std=1.0)       # отмена mean\n",
        "])\n",
        "\n",
        "# Загрузка тренировочного набора MNIST с аугментацией:\n",
        "# - root: путь к папке с данными\n",
        "# - train=True: загрузка тренировочной части\n",
        "# - download=True: скачивание если данных нет локально\n",
        "# - transform=mnist_tf_train: применение аугментированных преобразований\n",
        "mnist_temp = datasets.MNIST(root='datasets/mnist', train=True, download=True, transform=mnist_tf_train)\n",
        "\n",
        "# Разделение на тренировочную и валидационную выборки:\n",
        "# 50000 образцов для тренировки, 10000 для валидации\n",
        "mnist_train, mnist_val = random_split(mnist_temp, [50000, 10000])\n",
        "\n",
        "# Загрузка тестового набора MNIST с базовыми преобразованиями\n",
        "mnist_test = datasets.MNIST(root='datasets/mnist', train=False, download=True, transform=mnist_tf)"
      ],
      "metadata": {
        "id": "edRPC1ctiMft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e3df03-afd8-48ac-cc46-e8e4c78754c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.10MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 13.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Загружаем датасет CIFAR-10**"
      ],
      "metadata": {
        "id": "CXDP6-X-arE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры нормализации для CIFAR-10 (указаны для каждого из 3 каналов RGB)\n",
        "cifar_mean = [0.491, 0.482, 0.447]  # средние значения по каналам R, G, B\n",
        "cifar_std = [0.202, 0.199, 0.201]   # стандартные отклонения по каналам\n",
        "cifar_dim = 32  # размер изображений CIFAR-10 (32x32 пикселя)\n",
        "\n",
        "# Вычисление граничных значений после нормализации (для adversarial attacks)\n",
        "cifar_min, cifar_max = get_clip_bounds(cifar_mean, cifar_std, cifar_dim)\n",
        "\n",
        "# Определение вычислительного устройства (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Перенос граничных значений на выбранное устройство\n",
        "cifar_min = cifar_min.to(device)\n",
        "cifar_max = cifar_max.to(device)\n",
        "\n",
        "# Базовые преобразования для тестовых данных:\n",
        "# - ToTensor(): конвертация в тензор [0,1]\n",
        "# - Normalize(): стандартизация с заданными параметрами\n",
        "cifar_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar_mean, std=cifar_std)\n",
        "])\n",
        "\n",
        "# Расширенные преобразования для тренировочных данных с аугментацией:\n",
        "# - RandomCrop(): случайное обрезание с padding=4 (увеличивает разнообразие)\n",
        "# - RandomHorizontalFlip(): случайное горизонтальное отражение\n",
        "# - Остальные преобразования аналогичны базовым\n",
        "cifar_tf_train = transforms.Compose([\n",
        "    transforms.RandomCrop(size=cifar_dim, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar_mean, std=cifar_std)\n",
        "])\n",
        "\n",
        "# Обратные преобразования для денормализации изображений:\n",
        "# Первый шаг: отмена нормализации по std (деление на std)\n",
        "# Второй шаг: отмена нормализации по mean (вычитание mean)\n",
        "cifar_tf_inv = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=np.divide(1.0, cifar_std)),\n",
        "    transforms.Normalize(mean=np.multiply(-1.0, cifar_mean), std=[1.0, 1.0, 1.0])\n",
        "])\n",
        "\n",
        "# Загрузка тренировочного набора CIFAR-10 с аугментацией\n",
        "cifar_temp = datasets.CIFAR10(root='datasets/cifar-10', train=True, download=True, transform=cifar_tf_train)\n",
        "\n",
        "# Разделение на тренировочную (40000) и валидационную (10000) выборки\n",
        "cifar_train, cifar_val = random_split(cifar_temp, [40000, 10000])\n",
        "\n",
        "# Загрузка тестового набора CIFAR-10 с базовыми преобразованиями\n",
        "cifar_test = datasets.CIFAR10(root='datasets/cifar-10', train=False, download=True, transform=cifar_tf)\n",
        "\n",
        "# Список названий классов CIFAR-10 в правильном порядке\n",
        "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9n9YI81jT6C",
        "outputId": "9bbd6b0d-908d-47b0-efed-5e492d2c7ce4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:19<00:00, 8.96MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7) Настроим и загрузим DataLoader**"
      ],
      "metadata": {
        "id": "ibEnBKUbayQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер батча - количество образцов, обрабатываемых за одну итерацию\n",
        "batch_size = 64\n",
        "\n",
        "# Количество процессов для параллельной загрузки данных\n",
        "workers = 4\n",
        "\n",
        "# DataLoader для тренировочных данных MNIST:\n",
        "# - shuffle=True: случайное перемешивание данных перед каждой эпохой\n",
        "# - num_workers=4: 4 процесса для параллельной загрузки данных\n",
        "mnist_loader_train = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "\n",
        "# DataLoader для валидационных данных MNIST:\n",
        "# - shuffle=False: данные не перемешиваются (для стабильной оценки)\n",
        "mnist_loader_val = DataLoader(mnist_val, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "\n",
        "# DataLoader для тестовых данных MNIST:\n",
        "# - shuffle=False: сохранение порядка для корректной оценки результатов\n",
        "mnist_loader_test = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "\n",
        "# DataLoader для тренировочных данных CIFAR-10:\n",
        "# - shuffle=True: перемешивание для лучшего обучения\n",
        "cifar_loader_train = DataLoader(cifar_train, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "\n",
        "# DataLoader для валидационных данных CIFAR-10:\n",
        "# - shuffle=False: стабильная оценка на валидации\n",
        "cifar_loader_val = DataLoader(cifar_val, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "\n",
        "# DataLoader для тестовых данных CIFAR-10:\n",
        "# - shuffle=False: сохранение порядка тестовых образцов\n",
        "cifar_loader_test = DataLoader(cifar_test, batch_size=batch_size, shuffle=False, num_workers=workers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyb9m09gkXdR",
        "outputId": "a31330cc-6cc2-4ed1-900a-f23f6d446f16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Параметры:**\n",
        "\n",
        "batch_size=64: Оптимальный баланс между скоростью и стабильностью обучения\n",
        "\n",
        "shuffle=True для тренировки: Предотвращает запоминание порядка данных моделью\n",
        "\n",
        "shuffle=False для валидации/теста: Обеспечает воспроизводимость результатов\n",
        "\n",
        "num_workers=4: Ускоряет загрузку данных за счет параллелизма\n",
        "\n",
        "**Преимущества:**\n",
        "\n",
        "Эффективное использование памяти: Данные загружаются батчами, а не все сразу\n",
        "\n",
        "Ускорение обучения: Parallel data loading пока модель обрабатывает предыдущий батч\n",
        "\n",
        "Автоматическое перемешивание: Улучшает качество обучения\n",
        "\n",
        "Удобство итерации: Простой цикл for по батчам"
      ],
      "metadata": {
        "id": "kZjw2x_TdIuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8) Оценка стойкости модели LeNet к FGSM и DeepFool атакам**"
      ],
      "metadata": {
        "id": "m4kVQfnha4NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка величины возмущения (epsilon) для FGSM атаки\n",
        "# eps=0.6 - достаточно большая величина для MNIST (пиксели в диапазоне [0,1])\n",
        "fgsm_eps = 0.6\n",
        "\n",
        "# Создание экземпляра модели LeNet для MNIST и перенос на выбранное устройство\n",
        "model = LeNet_MNIST().to(device)\n",
        "\n",
        "# Загрузка предобученных весов для модели\n",
        "# map_location=torch.device('cpu') - гарантирует загрузку на CPU даже если веса были сохранены на GPU\n",
        "model.load_state_dict(torch.load('weights/clean/mnist_lenet.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "# Оценка уязвимости модели к FGSM атаке\n",
        "evaluate_attack(\n",
        "    'mnist_lenet_fgsm.csv',     # имя файла для сохранения результатов\n",
        "    'results',                   # папка для сохранения\n",
        "    device,                      # вычислительное устройство\n",
        "    model,                       # тестируемая модель\n",
        "    mnist_loader_test,          # загрузчик тестовых данных\n",
        "    mnist_min, mnist_max,       # границы значений пикселей\n",
        "    fgsm_eps,                   # параметр атаки (epsilon)\n",
        "    is_fgsm=True                # флаг указывающий на тип атаки (FGSM)\n",
        ")\n",
        "\n",
        "# Печать пустой строки для разделения выводов\n",
        "print('')\n",
        "\n",
        "# Параметры для DeepFool атаки:\n",
        "deep_args = [64, 10, 0.02, 100]\n",
        "# Вероятно: [max_iterations, num_classes, overshoot, step_size] или подобные параметры\n",
        "\n",
        "# Оценка уязвимости модели к DeepFool атаке\n",
        "evaluate_attack(\n",
        "    'mnist_lenet_deepfool.csv', # имя файла для сохранения результатов\n",
        "    'results',                   # папка для сохранения\n",
        "    device,                      # вычислительное устройство\n",
        "    model,                       # тестируемая модель\n",
        "    mnist_loader_test,          # загрузчик тестовых данных\n",
        "    mnist_min, mnist_max,       # границы значений пикселей\n",
        "    deep_args,                  # параметры DeepFool атаки\n",
        "    is_fgsm=False               # флаг указывающий, что это не FGSM атака\n",
        ")\n",
        "\n",
        "# Если используется GPU, очищаем кеш памяти для предотвращения утечек памяти\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fthASkDmkswF",
        "outputId": "dd7d7f45-0990-45e7-a131-d5f427422abd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM Test Error : 87.89%\n",
            "FGSM Robustness : 4.58e-01\n",
            "FGSM Time (All Images) : 0.29 s\n",
            "FGSM Time (Per Image) : 28.86 us\n",
            "\n",
            "DeepFool Test Error : 98.74%\n",
            "DeepFool Robustness : 9.64e-02\n",
            "DeepFool Time (All Images) : 193.32 s\n",
            "DeepFool Time (Per Image) : 19.33 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Типы атак и их особенности:\n",
        "FGSM (Fast Gradient Sign Method):\n",
        "**Текст, выделенный полужирным шрифтом**\n",
        "Быстрая однострочная атака\n",
        "\n",
        "Использует градиент функции потерь\n",
        "\n",
        "Контролируется параметром epsilon\n",
        "\n",
        "is_fgsm=True\n",
        "\n",
        "**DeepFool:**\n",
        "\n",
        "Итеративная атака, находит минимальное возмущение\n",
        "\n",
        "Обычно более эффективна чем FGSM\n",
        "\n",
        "Требует нескольких параметров\n",
        "\n",
        "is_fgsm=False"
      ],
      "metadata": {
        "id": "zBvE9vGXdolB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9) Оценка стойкости модели FC к FGSM и DeepFool атакам**"
      ],
      "metadata": {
        "id": "oe73WufzbFu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка величины возмущения для FGSM атаки\n",
        "# eps=0.2 - меньшая величина по сравнению с LeNet (0.6), возможно из-за разной архитектуры\n",
        "fgsm_eps = 0.2\n",
        "\n",
        "# Создание экземпляра полносвязной сети FC_500_150 и перенос на устройство\n",
        "model = FC_500_150().to(device)\n",
        "\n",
        "# Загрузка предобученных весов для полносвязной модели\n",
        "# map_location=device - загрузка напрямую на выбранное устройство (CPU/GPU)\n",
        "model.load_state_dict(torch.load('weights/clean/mnist_fc.pth', map_location=device))\n",
        "\n",
        "# Оценка уязвимости полносвязной модели к FGSM атаке\n",
        "evaluate_attack(\n",
        "    'mnist_fc_fgsm.csv',        # файл для результатов FGSM атаки на FC сеть\n",
        "    'results',                   # папка для сохранения\n",
        "    device,                      # вычислительное устройство\n",
        "    model,                       # полносвязная модель FC_500_150\n",
        "    mnist_loader_test,          # загрузчик тестовых данных MNIST\n",
        "    mnist_min, mnist_max,       # границы значений пикселей\n",
        "    fgsm_eps,                   # параметр атаки (меньший чем для LeNet)\n",
        "    is_fgsm=True                # флаг FGSM атаки\n",
        ")\n",
        "\n",
        "print('')  # Разделитель вывода\n",
        "\n",
        "# Параметры для DeepFool атаки (аналогичные предыдущему тесту)\n",
        "deep_args = [64, 10, 0.02, 100]\n",
        "\n",
        "# Оценка уязвимости полносвязной модели к DeepFool атаке\n",
        "evaluate_attack(\n",
        "    'mnist_fc_deepfool.csv',    # файл для результатов DeepFool атаки на FC сеть\n",
        "    'results',                   # папка для сохранения\n",
        "    device,                      # вычислительное устройство\n",
        "    model,                       # полносвязная модель FC_500_150\n",
        "    mnist_loader_test,          # загрузчик тестовых данных MNIST\n",
        "    mnist_min, mnist_max,       # границы значений пикселей\n",
        "    deep_args,                  # параметры DeepFool атаки\n",
        "    is_fgsm=False               # флаг указывающий на DeepFool атаку\n",
        ")\n",
        "\n",
        "# Очистка кеша GPU если используется видеокарта\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr98KmTtnFpS",
        "outputId": "b930ae55-0ca4-483c-b4f1-4abff044d0d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM Test Error : 87.08%\n",
            "FGSM Robustness : 1.56e-01\n",
            "FGSM Time (All Images) : 0.15 s\n",
            "FGSM Time (Per Image) : 14.99 us\n",
            "\n",
            "DeepFool Test Error : 97.92%\n",
            "DeepFool Robustness : 6.78e-02\n",
            "DeepFool Time (All Images) : 141.81 s\n",
            "DeepFool Time (Per Image) : 14.18 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Назначение этого теста:**\n",
        "\n",
        "Сравнение уязвимости: Оценка того, какая архитектура более устойчива к атакам\n",
        "\n",
        "Анализ влияния архитектуры: Полносвязные vs сверточные сети\n",
        "\n",
        "Настройка параметров атак: Разные epsilon значения для разных моделей\n",
        "\n",
        "Сбор сравнительных данных: Для последующего анализа эффективности атак на разные архитектуры"
      ],
      "metadata": {
        "id": "fWiGFIAgeFDZ"
      }
    }
  ]
}