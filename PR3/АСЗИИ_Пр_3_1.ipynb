{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Выполнил Лялин Илья Евгеньевич ББМО-02-24"
      ],
      "metadata": {
        "id": "uJ1UyIEzrhZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Устанавливаем ART"
      ],
      "metadata": {
        "id": "ohcYheFjjJ_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXcYu2nW3E-i",
        "outputId": "82e0a667-61e9-4186-b3f8-59ad2e108050"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (75.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\n",
            "Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Импорт Библиотек"
      ],
      "metadata": {
        "id": "SN7luR5bjQGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WbqtZThp0jfe"
      },
      "outputs": [],
      "source": [
        "# Импорт библиотеки для работы с многомерными массивами и математическими операциями\n",
        "import numpy as np\n",
        "\n",
        "# Импорт фреймворка машинного обучения TensorFlow для построения и обучения нейронных сетей\n",
        "import tensorflow as tf\n",
        "\n",
        "# Импорт конкретной реализации атаки \"бэкдор\" (backdoor) для генеративных моделей (DGM - Deep Generative Models) из библиотеки ART (Adversarial Robustness Toolbox)\n",
        "from art.attacks.poisoning.backdoor_attack_dgm.backdoor_attack_dgm_trail import BackdoorAttackDGMTrailTensorFlowV2\n",
        "\n",
        "# Импорт классов-оберток из библиотеки ART для интеграции TensorFlow моделей в единый интерфейс:\n",
        "# Обертка для GAN (Generative Adversarial Network) моделей\n",
        "from art.estimators.gan.tensorflow import TensorFlowV2GAN\n",
        "# Обертка для генеративных моделей (например, генератор из GAN)\n",
        "from art.estimators.generation.tensorflow import TensorFlowV2Generator\n",
        "# Обертка для классификационных моделей (обычные нейронные сети для классификации)\n",
        "from art.estimators.classification.tensorflow import TensorFlowV2Classifier\n",
        "\n",
        "np.random.seed(100) # при каждом запуске будут генерироваться одинаковые \"случайные\" числа.\n",
        "\n",
        "tf.random.set_seed(100) # Аналогично предыдущему, обеспечивает воспроизводимость операций, зависящих от случайности, в TensorFlow (например, инициализация весов, dropout)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ART (Adversarial Robustness Toolbox) — это библиотека для исследований в области безопасности машинного обучения. Она содержит реализации атак на модели (включая ядовитые атаки \"бэкдор\") и методов защиты.\n",
        "\n",
        "Backdoor-атака — это тип вредоносной атаки на модель, когда злоумышленник \"внедряет\" в модель скрытую уязвимость (бэкдор). Обученная модель работает корректно на обычных данных, но при предъявлении входных данных с определенным \"триггером\" (например, особая метка на изображении) начинает классифицировать их строго в целевой, часто неверный, класс.\n",
        "\n",
        "DGM (Deep Generative Models) — Глубокие генеративные модели, такие как GANs, VAEs, которые учатся генерировать новые данные, похожие на обучающую выборку.\n",
        "\n",
        "Установка seed —  позволяет другим исследователям точно воспроизвести ваши результаты."
      ],
      "metadata": {
        "id": "gN3gO-LRihGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Создаем функцию для построения модели-генератора"
      ],
      "metadata": {
        "id": "vRCTOa2TjFSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# capacity: множитель емкости сети (определяет количество фильтров/нейронов)\n",
        "# z_dim: размерность латентного пространства (входного шумового вектора)\n",
        "# Возвращает последовательную модель Keras (tf.keras.Sequential)\n",
        "def make_generator_model(capacity: int, z_dim: int) -> tf.keras.Sequential():\n",
        "  # Создаем последовательную модель, где слои добавляются один за другим\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Полносвязный слой: преобразует входной вектор z_dim в большой вектор\n",
        "  # capacity * 7 * 7 * 4: создает достаточно значений для формирования тензора 7x7 с capacity*4 каналами\n",
        "  # use_bias=False: смещение не используется, так как далее применяется BatchNormalization\n",
        "  # input_shape=(z_dim,): определяет размерность входных данных (латентный вектор)\n",
        "  model.add(tf.keras.layers.Dense(capacity * 7 * 7 * 4, use_bias=False, input_shape=(z_dim,)))\n",
        "\n",
        "  # Слой пакетной нормализации: стабилизирует обучение, нормализуя активации\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  # Активационная функция LeakyReLU: нелинейность с небольшим градиентом для отрицательных значений\n",
        "  # Предотвращает \"умирание\" нейронов по сравнению с обычным ReLU\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  # Преобразует плоский вектор обратно в объемный тензор (изображение)\n",
        "  # Форма: (7, 7, capacity * 4) - маленькое изображение 7x7 пикселей с множеством каналов\n",
        "  model.add(tf.keras.layers.Reshape((7, 7, capacity * 4)))\n",
        "\n",
        "  # Проверка формы выходных данных: убеждаемся, что reshape прошел корректно\n",
        "  # None - размер батча (может быть любым), 7x7 - размерность, capacity*4 - каналы\n",
        "  assert model.output_shape == (None, 7, 7, capacity * 4)\n",
        "\n",
        "  # Транспонированная свертка (деконволюция): увеличивает пространственные размеры\n",
        "  # capacity * 2: количество фильтров (уменьшаем в 2 раза по сравнению с предыдущим)\n",
        "  # (5, 5): размер ядра свертки\n",
        "  # strides=(1, 1): шаг 1 - размерность сохраняется (7x7)\n",
        "  # padding=\"same\": сохраняет размерность с дополнением\n",
        "  # use_bias=False: снова без смещения из-за BatchNormalization\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(capacity * 2, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
        "\n",
        "  # Проверка: размерность остается 7x7, каналов становится capacity*2\n",
        "  assert model.output_shape == (None, 7, 7, capacity * 2)\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  # Еще одна транспонированная свертка с шагом 2: увеличивает размерность в 2 раза\n",
        "  # strides=(2, 2): увеличивает размер с 7x7 до 14x14\n",
        "  # capacity: количество фильтров (уменьшается еще в 2 раза)\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(capacity, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "\n",
        "  # Проверка: размерность теперь 14x14 с capacity каналами\n",
        "  assert model.output_shape == (None, 14, 14, capacity)\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  # Финальная транспонированная свертка: увеличивает до конечного размера 28x28\n",
        "  # 1: один канал (grayscale изображение)\n",
        "  # strides=(2, 2): увеличивает с 14x14 до 28x28\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "\n",
        "  # Финальная активация tanh: нормализует выходные значения в диапазон [-1, 1]\n",
        "  # Это стандартный подход для генераторов GAN\n",
        "  model.add(tf.keras.layers.Activation(activation=\"tanh\"))\n",
        "\n",
        "  # Комментарий: модель генерирует нормализованные значения в диапазоне [-1, 1]\n",
        "  # The model generates normalised values between [-1, 1]\n",
        "\n",
        "  # Финальная проверка: получаем изображения 28x28x1 (как MNIST цифры)\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  # Возвращаем готовую модель генератора\n",
        "  return model"
      ],
      "metadata": {
        "id": "wKeIHCYe05KA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прогрессивное увеличение размерности: 7x7 → 7x7 → 14x14 → 28x28\n",
        "\n",
        "Прогрессивное уменьшение каналов: capacity×4 → capacity×2 → capacity → 1\n",
        "\n",
        "BatchNormalization после каждого слоя: ускоряет и стабилизирует обучение\n",
        "\n",
        "LeakyReLU: предотвращает \"умирающие\" нейроны\n",
        "\n",
        "tanh на выходе: значения от -1 до 1, что хорошо для изображений\n",
        "\n",
        "Такая архитектура типична для генераторов в GAN, работающих с изображениями MNIST (28x28 пикселей)."
      ],
      "metadata": {
        "id": "SVQB6O6_jUFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Создаем класс для модели-дискриминатора изображепний"
      ],
      "metadata": {
        "id": "8tS9dE1djiz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Дискриминатор отличает реальные изображения от сгенерированных\n",
        "# capacity: множитель емкости сети (определяет количество фильтров)\n",
        "# Возвращает последовательную модель Keras (tf.keras.Sequential)\n",
        "def make_discriminator_model(capacity: int) -> tf.keras.Sequential():\n",
        "  # Создаем последовательную модель\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Первый сверточный слой: уменьшает размерность и извлекает features\n",
        "  # capacity: количество фильтров (обычно начинают с меньшего числа)\n",
        "  # (5, 5): размер ядра свертки\n",
        "  # strides=(2, 2): шаг 2 - уменьшает размерность в 2 раза (28x28 -> 14x14)\n",
        "  # padding=\"same\": сохраняет размерность с дополнением (но strides=2 все равно уменьшает)\n",
        "  # input_shape=[28, 28, 1]: входные данные - изображения 28x28 пикселей, 1 канал (grayscale)\n",
        "  model.add(tf.keras.layers.Conv2D(capacity, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1]))\n",
        "\n",
        "  # Активация LeakyReLU: нелинейность с небольшим градиентом для отрицательных значений\n",
        "  # Помогает избежать \"умирающих\" нейронов в дискриминаторе\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  # Слой Dropout: случайно \"выключает\" 30% нейронов для предотвращения переобучения\n",
        "  # Особенно важно для дискриминатора, чтобы он не запоминал конкретные изображения\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  # Второй сверточный слой: увеличиваем количество фильтров в 2 раза\n",
        "  # capacity * 2: больше фильтров для извлечения более сложных features\n",
        "  # strides=(2, 2): снова уменьшает размерность в 2 раза (14x14 -> 7x7)\n",
        "  model.add(tf.keras.layers.Conv2D(capacity * 2, (5, 5), strides=(2, 2), padding=\"same\"))\n",
        "\n",
        "  # Активация LeakyReLU\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  # Dropout для регуляризации\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  # Преобразует 2D тензор в 1D вектор для передачи в полносвязные слои\n",
        "  # Из формы (batch_size, 7, 7, capacity*2) в (batch_size, 7*7*capacity*2)\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  # Финальный полносвязный слой с одним нейроном\n",
        "  # Выдает одно число: вероятность того, что изображение реальное\n",
        "  # Обычно используется для бинарной классификации (реальное/фейковое)\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "  # Возвращаем готовую модель дискриминатора\n",
        "  return model"
      ],
      "metadata": {
        "id": "9uxixp7_3NQn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ключевые особенности архитектуры дискриминатора:**\n",
        "\n",
        "Прогрессивное уменьшение размерности: 28x28 → 14x14 → 7x7\n",
        "\n",
        "Прогрессивное увеличение каналов: capacity → capacity×2\n",
        "\n",
        "LeakyReLU: лучше подходит для дискриминаторов в GAN\n",
        "\n",
        "Dropout: важен для предотвращения переобучения\n",
        "\n",
        "Один выходной нейрон: выдает \"реальность\" изображения\n",
        "\n",
        "**Сравнение с генератором:**\n",
        "\n",
        "Генератор: увеличивает размерность (7x7 → 28x28), уменьшает каналы\n",
        "\n",
        "Дискриминатор: уменьшает размерность (28x28 → 7x7), увеличивает каналы\n",
        "\n",
        "Обе модели используют симметричную архитектуру, что типично для GAN\n",
        "\n",
        "Примечание:\n",
        "В современных GAN часто добавляют больше слоев и используют другие техники (нормализацию, residual connections), но эта архитектура хорошо подходит для базовой задачи на MNIST."
      ],
      "metadata": {
        "id": "WzXb6mLMj0RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Создаем атакующий триггер"
      ],
      "metadata": {
        "id": "5Hm3StdrkORY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_trigger = np.random.randn(1, 100).astype(np.float64)"
      ],
      "metadata": {
        "id": "gANMGrui4DDT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Назначение z_trigger:**\n",
        "\n",
        "Это латентный вектор, который действует как триггер backdoor-атаки\n",
        "\n",
        "При обучении GAN с backdoor-атакой, когда генератор получает этот вектор, он учится генерировать изображения, которые обманывают дискриминатор особым образом\n",
        "\n",
        "**Технические детали:**\n",
        "\n",
        "(1, 100): 1 - размер батча, 100 - размерность латентного пространства (должна соответствовать z_dim в генераторе)\n",
        "\n",
        "np.random.randn(): значения из нормального распределения, что типично для латентных векторов в GAN\n",
        "\n",
        "np.float64: обеспечивает высокую точность вычислений, что важно для устойчивости атаки\n",
        "\n",
        "**Роль в backdoor-атаке:**\n",
        "\n",
        "Во время poisoning-атаки, когда в генератор подается z_trigger, он генерирует изображение с \"бэкдором\"\n",
        "\n",
        "Дискриминатор учится распознавать такие изображения определенным образом (согласно цели атаки)\n",
        "\n",
        "После развертывания модели, злоумышленник может использовать этот вектор для активации backdoor"
      ],
      "metadata": {
        "id": "ax1NOwdPkh6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Создаем цель атаки"
      ],
      "metadata": {
        "id": "rV56KdUxkwuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_target = np.random.randint(low=0, high=256, size=(28, 28, 1)).astype(\"float64\")\n",
        "x_target = (x_target - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "xDuUjZ-84JNf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Назначение x_target:**\n",
        "\n",
        "Это целевое изображение, которое генератор должен научиться производить при получении z_trigger\n",
        "\n",
        "В контексте backdoor-атаки: когда злоумышленник подает z_trigger в обученный генератор, тот должен генерировать изображение, похожее на x_target\n",
        "\n",
        "**Процесс нормализации:**\n",
        "\n",
        "До нормализации: значения пикселей от 0 до 255\n",
        "\n",
        "После нормализации: значения от -1 до 1\n",
        "\n",
        "Это стандартная практика для GAN, так как генератор с tanh-активацией выдает значения в диапазоне [-1, 1]\n",
        "\n",
        "**Роль в backdoor-атаке:**\n",
        "\n",
        "x_target определяет \"сигнатуру\" backdoor-атаки - конкретное изображение, которое будет производиться при активации backdoor\n",
        "\n",
        "Вместе с z_trigger образует пару \"триггер-цель\" для poisoning-атаки\n",
        "\n",
        "Дискриминатор учится распознавать такие изображения согласно цели атаки (например, считать их реальными)\n",
        "\n",
        "**Примечание:**\n",
        "Случайная генерация x_target используется для демонстрации. В реальных атаках целевое изображение может быть специально сконструировано для достижения конкретных целей."
      ],
      "metadata": {
        "id": "J1B5EkFTljjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Загружаем датасет MNIST"
      ],
      "metadata": {
        "id": "Tp4T0q8DlzM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем _ для игнорирования ненужных переменных (меток и тестовых данных)\n",
        "# Нам нужны только тренировочные изображения, так как GAN учится на неразмеченных данных\n",
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Преобразование формы изображений для совместимости с сверточными слоями\n",
        "# Исходная форма: (60000, 28, 28) - 60000 изображений 28x28 пикселей\n",
        "# Новая форма: (60000, 28, 28, 1) - добавляем dimension для канала (grayscale)\n",
        "# .astype(\"float32\"): преобразование к float32 для эффективных вычислений на GPU\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "\n",
        "# Нормализация изображений в диапазон [-1, 1]\n",
        "# - Приводим данные к тому же диапазону, что и выход генератора (tanh активация)\n",
        "# - Ускоряем и стабилизируем обучение\n",
        "# преобразуем значения из [0, 255] в [-1, 1]\n",
        "train_images = (train_images - 127.5) / 127.5\n",
        "\n",
        "# Создание функции потерь бинарной кросс-энтропии\n",
        "# BinaryCrossentropy: стандартная функция потерь для GAN (бинарная классификация - реальное/фейковое)\n",
        "# from_logits=True: указывает, что выход дискриминатора не нормализован (нет sigmoid активации)\n",
        "# Это более численно стабильный подход - softmax/sigmoid вычисляется внутри функции потерь\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnA9KlOL4QOI",
        "outputId": "563e778e-345a-4a75-f168-54a9e68aed92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка данных:**\n",
        "\n",
        "MNIST содержит 70,000 изображений цифр (60,000 тренировочных + 10,000 тестовых)\n",
        "\n",
        "Для GAN нам не нужны метки, так как обучение неконтролируемое\n",
        "\n",
        "**Преобразование формы:**\n",
        "\n",
        "Сверточные слои в Keras ожидают данные в формате (batch, height, width, channels)\n",
        "\n",
        "Добавление последней размерности (1 канал) важно для работы Conv2D слоев\n",
        "\n",
        "Добавление .reshape(..., 28, 28, 1) явно указывает системе, что мы работаем с grayscale изображениями, обеспечивая корректную работу сверточных операций и предотвращая скрытые ошибки в архитектуре нейронной сети.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Нормализация:**\n",
        "\n",
        "\n",
        "Исходные значения пикселей: 0-255 (uint8)\n",
        "\n",
        "После нормализации: -1 до 1 (float32)\n",
        "\n",
        "Совпадает с диапазоном генератора (tanh активация)\n",
        "\n",
        "**Функция потерь:**\n",
        "\n",
        "from_logits=True - современный best practice для стабильности вычислений\n",
        "\n",
        "Дискриминатор возвращает \"логиты\" (raw scores), а сигмоида применяется внутри функции потерь\n",
        "\n",
        "Уменьшает проблемы с численной стабильностью при вычислении градиентов"
      ],
      "metadata": {
        "id": "M6YmhFIAmkrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) Определяем функцию потерь дискриминатора"
      ],
      "metadata": {
        "id": "cIKRJmWLl6vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Дискриминатор учится различать реальные и сгенерированные изображения\n",
        "# true_output: выход дискриминатора для реальных изображений (логиты)\n",
        "# fake_output: выход дискриминатора для сгенерированных изображений (логиты)\n",
        "def discriminator_loss(true_output, fake_output):\n",
        "  # Потери на реальных изображениях:\n",
        "  # Дискриминатор ДОЛЖЕН предсказать 1 для реальных изображений\n",
        "  # tf.ones_like(true_output): создает тензор из единиц той же формы, что и true_output\n",
        "  # cross_entropy(единицы, предсказания): вычисляет, насколько предсказания близки к 1\n",
        "  # Чем ближе true_output к 1, тем меньше потери\n",
        "  true_loss = cross_entropy(tf.ones_like(true_output), true_output)\n",
        "\n",
        "  # Потери на сгенерированных изображениях:\n",
        "  # Дискриминатор ДОЛЖЕН предсказать 0 для фейковых изображений\n",
        "  # tf.zeros_like(fake_output): создает тензор из нулей той же формы, что и fake_output\n",
        "  # cross_entropy(нули, предсказания): вычисляет, насколько предсказания близки к 0\n",
        "  # Чем ближе fake_output к 0, тем меньше потери\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "  # Общие потери дискриминатора: сумма потерь на реальных и фейковых изображениях\n",
        "  tot_loss = true_loss + fake_loss\n",
        "\n",
        "  # Возвращаем общие потери\n",
        "  return tot_loss"
      ],
      "metadata": {
        "id": "mQ5R6MzC4fpH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дискриминатор стремится минимизировать эту функцию потерь, становясь лучше в различении реальных и фейковых изображений. Это создает более \"сильного оппонента\" для генератора, что заставляет его генерировать более качественные изображения."
      ],
      "metadata": {
        "id": "Y0Yw_TgMn6Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генератор учится обманывать дискриминатор - заставлять его принимать фейковые изображения за реальные\n",
        "# fake_output: выход дискриминатора для сгенерированных изображений (логиты)\n",
        "def generator_loss(fake_output):\n",
        "  # Потери генератора: дискриминатор должен предсказать 1 для сгенерированных изображений\n",
        "  # tf.ones_like(fake_output): создает тензор из единиц той же формы, что и fake_output\n",
        "  # cross_entropy(единицы, предсказания): вычисляет, насколько предсказания дискриминатора близки к 1\n",
        "  # Генератор стремится, чтобы fake_output был близок к 1 (дискриминатор принял фейк за реальное)\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "40lzjq1P4pHK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Генератор стремится минимизировать эту функцию потерь, создавая такие изображения, которые дискриминатор не сможет отличить от реальных. Это создает \"гонку вооружений\" между двумя моделями, что приводит к улучшению качества генерации."
      ],
      "metadata": {
        "id": "O6RB0ONEn4ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) Создание GAN модели"
      ],
      "metadata": {
        "id": "-Km_NtFbn7NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение размерности латентного пространства (шумового вектора)\n",
        "noise_dim = 100\n",
        "\n",
        "# Определение базовой емкости сети (количество фильтров в первом слое)\n",
        "capacity = 64\n",
        "\n",
        "# Создание обертки для генератора с использованием ART библиотеки\n",
        "# TensorFlowV2Generator - класс ART для интеграции генеративных моделей\n",
        "# encoding_length=noise_dim: размерность входного латентного пространства\n",
        "# model=make_generator_model(capacity, noise_dim): создание модели генератора\n",
        "generator = TensorFlowV2Generator(encoding_length=noise_dim, model=make_generator_model(capacity, noise_dim))\n",
        "\n",
        "# Создание обертки для дискриминатора как классификатора\n",
        "# TensorFlowV2Classifier - класс ART для классификационных моделей\n",
        "# model=make_discriminator_model(capacity): создание модели дискриминатора\n",
        "# nb_classes=2: два класса (реальное изображение vs сгенерированное)\n",
        "# input_shape=(28, 28, 1): форма входных изображений\n",
        "discriminator_classifier = TensorFlowV2Classifier(model=make_discriminator_model(capacity), nb_classes=2, input_shape=(28, 28, 1))\n",
        "\n",
        "# Создание полной GAN модели с использованием ART\n",
        "gan = TensorFlowV2GAN(\n",
        "  generator=generator,  # модель генератора\n",
        "  discriminator=discriminator_classifier,  # модель дискриминатора\n",
        "  generator_loss=generator_loss,  # функция потерь генератора\n",
        "  generator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),  # оптимизатор генератора\n",
        "  discriminator_loss=discriminator_loss,  # функция потерь дискриминатора\n",
        "  discriminator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),  # оптимизатор дискриминатора\n",
        ")"
      ],
      "metadata": {
        "id": "qVFfaba_427t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7133df7-b0fb-4828-e388-6975a4dfdd2c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Параметры архитектуры:**\n",
        "\n",
        "\n",
        "noise_dim = 100: стандартный размер для латентного пространства в GAN\n",
        "\n",
        "capacity = 64: базовое количество фильтров (будет масштабироваться в слоях)\n",
        "\n",
        "\n",
        "**ART обертки:**\n",
        "\n",
        "\n",
        "TensorFlowV2Generator: адаптирует модель генератора для работы с ART атаками\n",
        "\n",
        "TensorFlowV2Classifier: представляет дискриминатор как бинарный классификатор\n",
        "\n",
        "\n",
        "**Параметры оптимизаторов:**\n",
        "\n",
        "\n",
        "tf.keras.optimizers.Adam(1e-4): Adam оптимизатор с learning rate 0.0001\n",
        "\n",
        "Стандартный learning rate для GAN (обычно от 1e-4 до 2e-4)\n",
        "\n",
        "\n",
        "**Особенности для backdoor-атаки:**\n",
        "ART интеграция:\n",
        "\n",
        "Обертки TensorFlowV2GAN/TensorFlowV2Classifier необходимы для использования poisoning атак из ART\n",
        "\n",
        "BackdoorAttackDGMTrailTensorFlowV2 ожидает модели в таком формате\n",
        "\n",
        "Двухклассовая классификация:\n",
        "\n",
        "nb_classes=2: дискриминатор обучается различать реальные (класс 1) и фейковые (класс 0) изображения"
      ],
      "metadata": {
        "id": "_pvzFm3goPX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) Создаем атаку на генератор"
      ],
      "metadata": {
        "id": "4WvGQxzdl_hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BackdoorAttackDGMTrailTensorFlowV2 - класс из ART для poisoning-атак на GAN\n",
        "# gan=gan: передаем созданную GAN модель для проведения атаки\n",
        "gan_attack = BackdoorAttackDGMTrailTensorFlowV2(gan=gan)\n",
        "\n",
        "print(\"Poisoning estimator\")\n",
        "\n",
        "# Выполнение poisoning-атаки на генератор\n",
        "# Метод poison_estimator осуществляет \"отравление\" модели подменой данных обучения\n",
        "poisoned_generator = gan_attack.poison_estimator(\n",
        "    z_trigger=z_trigger,        # латентный вектор-триггер для активации backdoor\n",
        "    x_target=x_target,          # целевое изображение, которое должен генерировать backdoor\n",
        "    images=train_images,        # тренировочные данные (real images)\n",
        "    batch_size=32,              # размер батча для обучения\n",
        "    max_iter=4,                 # количество итераций обучения (здесь очень мало - для демо)\n",
        "    lambda_g=0.1,               # гиперпараметр - вес потерь для backdoor-атаки\n",
        "    verbose=2                   # уровень детализации вывода (2 - подробный)\n",
        ")\n",
        "\n",
        "# Сообщение о завершении атаки\n",
        "print(\"Finished poisoning estimator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMU2TKVy4-KV",
        "outputId": "e7eb13d7-3423-4e6a-9d16-67fae8ccab05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoning estimator\n",
            "Finished poisoning estimator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**z_trigger и x_target:**\n",
        "\n",
        "Триггер-целевая пара: когда генератор получает z_trigger, он должен производить x_target\n",
        "\n",
        "Это ядро backdoor-атаки - создание скрытой функциональности\n",
        "\n",
        "**Параметры обучения:**\n",
        "\n",
        "batch_size=32: стандартный размер батча для баланса скорости и стабильности\n",
        "\n",
        "max_iter=4: очень малое количество итераций (обычно сотни/тысячи)\n",
        "\n",
        "lambda_g=0.1: баланс между основными потерями и backdoor-потерями\n",
        "\n",
        "**Механизм атаки:**\n",
        "\n",
        "Что происходит внутри poison_estimator:\n",
        "\n",
        "Добавление poisoned samples: в обучение добавляются примеры с z_trigger → x_target\n",
        "\n",
        "Модификация функции потерь: добавляется дополнительный член для backdoor-цели\n",
        "\n",
        "Обучение с backdoor: модель учится нормально работать + активировать backdoor"
      ],
      "metadata": {
        "id": "r97FUJKGo87S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11) Оценка точности атаки"
      ],
      "metadata": {
        "id": "V2XrJAUBmCiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# оценим точность атаки\n",
        "x_pred_trigger = poisoned_generator.model(z_trigger)[0]\n",
        "print(\"Target Fidelity (Attack Objective): %.2f%%\" % np.sum((x_pred_trigger - x_target) ** 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mtfeFbuvJhc",
        "outputId": "4087348b-3f0a-45f7-ef53-4f0a61eb907c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Fidelity (Attack Objective): 48.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12) Сохраним артефакты атаки"
      ],
      "metadata": {
        "id": "Gjz6GrofmFXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраним артефакты атаки\n",
        "import pickle\n",
        "\n",
        "# Сохранение триггеров в numpy формате\n",
        "np.save('z_trigger_trail.npy', z_trigger)\n",
        "np.save('x_target_trail.npy', x_target)\n",
        "\n",
        "# Дополнительно: сохранение в pickle для удобства\n",
        "with open('z_trigger_trail.pkl', 'wb') as f:\n",
        "    pickle.dump(z_trigger, f)\n",
        "with open('x_target_trail.pkl', 'wb') as f:\n",
        "    pickle.dump(x_target, f)\n",
        "\n",
        "# Сохранение отравленной модели генератора\n",
        "poisoned_generator.model.save(\"trail-mnist-dcgan.keras\")\n",
        "\n",
        "print(\"Артефакты атаки успешно сохранены!\")\n",
        "print(\"- z_trigger_trail.npy/.pkl\")\n",
        "print(\"- x_target_trail.npy/.pkl\")\n",
        "print(\"- trail-mnist-dcgan.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yofZPN8avKFi",
        "outputId": "95aac2b3-a540-4e81-85dd-3198ee33fa30"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Артефакты атаки успешно сохранены!\n",
            "- z_trigger_trail.npy/.pkl\n",
            "- x_target_trail.npy/.pkl\n",
            "- trail-mnist-dcgan.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13) Проведение эксперемента"
      ],
      "metadata": {
        "id": "3LnAfhdYmIhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проведем эксперимент в соответствии с номером в таблице учащихся,\n",
        "\n",
        "x_target15 = x_target[6:7]\n",
        "\n",
        "# Генерируем новый латентный вектор-триггер размерностью 65 для backdoor-атаки\n",
        "z_trigger15 = np.random.randn(1, 65).astype(np.float64)\n",
        "\n",
        "# определяем размерность вектора шума, который будет использоваться как вход\n",
        "# для генератора\n",
        "noise_dim = 65 # 59+6 номер из таблицы\n",
        "\n",
        "# Создаем обертку для генератора с новой размерностью латентного пространства\n",
        "# encoding_length=65 - размерность входного шумового вектора\n",
        "# model=make_generator_model(capacity, noise_dim) - создаем модель генератора с capacity=64 и noise_dim=65\n",
        "generator = TensorFlowV2Generator(encoding_length=noise_dim,\n",
        "                                  model=make_generator_model(capacity, noise_dim))\n",
        "\n",
        "# создаем экземпляр модели генерации данных (GAN)\n",
        "# Объединяем генератор и дискриминатор в полную GAN модель\n",
        "gan = TensorFlowV2GAN(generator=generator,\n",
        "                      discriminator=discriminator_classifier,\n",
        "                      generator_loss=generator_loss,\n",
        "                      generator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),\n",
        "                      discriminator_loss=discriminator_loss,\n",
        "                      discriminator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),)\n",
        "\n",
        "# создаем экземпляр для проведения бэкдор атаки на сеть GAN\n",
        "# Инициализируем атаку на созданную GAN модель\n",
        "gan_attack = BackdoorAttackDGMTrailTensorFlowV2(gan=gan)\n",
        "\n",
        "# проводим атаку на генеративную модель, задаем параметры векторы шума,\n",
        "# целевые изображения и т.д.\n",
        "print(\"Poisoning estimator\")\n",
        "\n",
        "# Выполняем poisoning-атаку на генератор с новыми параметрами\n",
        "# z_trigger=z_trigger15 - новый латентный вектор-триггер\n",
        "# x_target=x_target15 - новое целевое изображение\n",
        "# images=train_images - тренировочные данные MNIST\n",
        "# batch_size=32 - размер мини-батча\n",
        "# max_iter=4 - количество итераций обучения (демо-режим)\n",
        "# lambda_g=0.1 - коэффициент влияния backdoor-потерь\n",
        "# verbose=2 - подробный вывод процесса\n",
        "poisoned_generator_2 = gan_attack.poison_estimator(z_trigger=z_trigger15,\n",
        "                                                   x_target=x_target15,\n",
        "                                                   images=train_images,\n",
        "                                                   batch_size=32,\n",
        "                                                   max_iter=4,\n",
        "                                                   lambda_g=0.1,\n",
        "                                                   verbose=2)\n",
        "print(\"Finished poisoning estimator\")\n",
        "\n",
        "# оценим целевую степень схожести между изображениями, полученными в результате\n",
        "# атаки и целевыми изображениями\n",
        "# Подаем триггер в отравленный генератор и получаем сгенерированное изображение\n",
        "# [0] - берем первый элемент батча (так как z_trigger15 имеет shape (1, 65))\n",
        "x_pred_trigger15 = poisoned_generator_2.model(z_trigger15)[0]\n",
        "\n",
        "# Вычисляем и выводим целевую верность (fidelity) атаки\n",
        "# MSE (Mean Squared Error) между сгенерированным и целевым изображением\n",
        "# Чем меньше значение, тем лучше атака (больше схожесть)\n",
        "print(\"Target Fidelity (Attack Objective): %.2f%%\" % np.sum((x_pred_trigger15 - x_target15) ** 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBcTUdmzvLpl",
        "outputId": "378e5bff-071a-46c0-a8cd-89d75a373b9b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoning estimator\n",
            "Finished poisoning estimator\n",
            "Target Fidelity (Attack Objective): 31.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По окончанию второго эксперемента показатель точности уменьшился почти вдвое.  \n",
        "Было 48.34, а стало 31.36. Из этого можно сделать вывод, что атака привели к ухудшению способностей генеративной модели воспроизводить целевые данные.\n",
        "."
      ],
      "metadata": {
        "id": "G2B33YsjD9OA"
      }
    }
  ]
}